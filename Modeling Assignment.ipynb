{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f5751a5e",
   "metadata": {},
   "source": [
    "# Justin Hamilton Modeling Portion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bbccabc",
   "metadata": {},
   "source": [
    "#### Importing Necessary Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f26ae493",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "362a6437",
   "metadata": {},
   "source": [
    "#### Making the dataframes for each of our CSV files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "10ffa8eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making Dataframes of each of the CSV Files\n",
    "\n",
    "# applicationtestDF = pd.read_csv(\"application_test.csv\")\n",
    "applicationtrainDF = pd.read_csv(\"application_train.csv\")\n",
    "# bureauDF = pd.read_csv(\"bureau.csv\")\n",
    "# bureaubalanceDF = pd.read_csv(\"bureau_balance.csv\")\n",
    "# creditcardbalanceDF = pd.read_csv(\"credit_card_balance.csv\")\n",
    "# installmentpaymentsDF = pd.read_csv(\"installments_payments.csv\")\n",
    "# poscashDF = pd.read_csv(\"POS_CASH_balance.csv\")\n",
    "# previousDF = pd.read_csv(\"previous_application.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f47bdd39",
   "metadata": {},
   "source": [
    "# Combining the Dataframes into one for analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b08a6a6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Combine the DataFrames\n",
    "# combined_df = pd.concat([applicationtestDF, applicationtrainDF, bureauDF, bureaubalanceDF,\n",
    "#                          creditcardbalanceDF, installmentpaymentsDF, poscashDF, previousDF])\n",
    "\n",
    "# # Remove missing values (NA)\n",
    "# combined_df = combined_df.dropna()\n",
    "\n",
    "# # Remove duplicates from the combined DataFrame\n",
    "# combined_df = combined_df.drop_duplicates()\n",
    "\n",
    "# # Reset the index\n",
    "# combined_df = combined_df.reset_index(drop=True)\n",
    "\n",
    "# Remove NA from applicationtestDF\n",
    "# applicationtestDF = applicationtestDF.dropna()\n",
    "\n",
    "# Remove NA from applicationtrainDF\n",
    "combined_df = applicationtrainDF.dropna()\n",
    "\n",
    "# Remove NA from bureauDF\n",
    "# bureauDF = bureauDF.dropna()\n",
    "\n",
    "# Remove NA from bureaubalanceDF\n",
    "# bureaubalanceDF = bureaubalanceDF.dropna()\n",
    "\n",
    "# Remove NA from creditcardbalanceDF\n",
    "# creditcardbalanceDF = creditcardbalanceDF.dropna()\n",
    "\n",
    "# Remove NA from installmentpaymentsDF\n",
    "# installmentpaymentsDF = installmentpaymentsDF.dropna()\n",
    "\n",
    "# Remove NA from poscashDF\n",
    "# poscashDF = poscashDF.dropna()\n",
    "\n",
    "# Remove NA from previousDF\n",
    "# previousDF = previousDF.dropna()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a1147531",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Print the head of the combined DataFrame\n",
    "# combined_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a0570349",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Print the data types of each column\n",
    "# combined_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4008ca41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Combine the DataFrames\n",
    "# combined_df = pd.concat([applicationtestDF, applicationtrainDF, bureauDF, bureaubalanceDF,\n",
    "#                          creditcardbalanceDF, installmentpaymentsDF, poscashDF, previousDF])\n",
    "\n",
    "# # Remove missing values (NA)\n",
    "# combined_df = combined_df.dropna()\n",
    "\n",
    "# # Remove duplicates from the DataFrame\n",
    "# df = df.drop_duplicates()\n",
    "\n",
    "# # Reset the index\n",
    "# combined_df = combined_df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b80e3327",
   "metadata": {},
   "source": [
    "Set up a training set and a validation set using application_train.csv data set to do cross-validation.  Alternatively you could perform cross-validation using a different framework, such as k-fold cross validation as implemented in modeling packages such as caret or tidymodels or scikit-learn. The model performance that matters, of course, is the estimated performance on the test set as well as the Kaggle score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "98550d07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Separate features and target variable\n",
    "X = combined_df.drop(\"TARGET\", axis=1)\n",
    "y = combined_df[\"TARGET\"]\n",
    "\n",
    "# Perform one-hot encoding on categorical variables\n",
    "X_encoded = pd.get_dummies(X, drop_first=True)\n",
    "\n",
    "# Split the data into train and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_encoded, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# # Split the validation set further into validation and test sets\n",
    "# X_val, X_test, y_val, y_test = train_test_split(X_val, y_val, test_size=0.5, random_state=42)\n",
    "\n",
    "# Create a RandomForestClassifier (or any other model of your choice)\n",
    "model = RandomForestClassifier()\n",
    "\n",
    "# Perform cross-validation\n",
    "scores = cross_val_score(model, X_train, y_train, cv=5)\n",
    "\n",
    "# Fit the model on the training data\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the validation set\n",
    "y_pred = model.predict(X_val)\n",
    "\n",
    "# Evaluate model performance\n",
    "accuracy = accuracy_score(y_val, y_pred)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6eeb4e8",
   "metadata": {},
   "source": [
    "Identify the performance benchmark established by the majority class classifier. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8a3570a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the occurrences of each class\n",
    "class_counts = y_train.value_counts()\n",
    "\n",
    "# Identify the majority class\n",
    "majority_class = class_counts.idxmax()\n",
    "\n",
    "# Calculate the accuracy of the majority class classifier\n",
    "accuracy_majority_class = class_counts[majority_class] / len(y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6149a51",
   "metadata": {},
   "source": [
    "Fit several different logistic regression models using different predictors. Do interaction terms improve the model?  Compare model performance using not just accuracy but also AUC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f6590bda",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jusha\\New folder\\envs\\daskpy\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\jusha\\New folder\\envs\\daskpy\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model without interactions:\n",
      "Accuracy: 0.9453805926786751\n",
      "AUC: 0.5837136617452824\n",
      "\n",
      "Model with interactions:\n",
      "Accuracy: 0.9453805926786751\n",
      "AUC: 0.5\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "\n",
    "# Generate interaction terms\n",
    "poly = PolynomialFeatures(interaction_only=True, include_bias=False)\n",
    "X_train_with_interactions = poly.fit_transform(X_train)\n",
    "\n",
    "# Fit logistic regression models with and without interaction terms\n",
    "model_without_interactions = LogisticRegression()\n",
    "model_without_interactions.fit(X_train, y_train)\n",
    "\n",
    "model_with_interactions = LogisticRegression()\n",
    "model_with_interactions.fit(X_train_with_interactions, y_train)\n",
    "\n",
    "# Prepare validation data\n",
    "X_val_with_interactions = poly.transform(X_val)\n",
    "\n",
    "# Make predictions on the validation set\n",
    "preds_without_interactions = model_without_interactions.predict(X_val)\n",
    "probs_without_interactions = model_without_interactions.predict_proba(X_val)[:, 1]\n",
    "\n",
    "preds_with_interactions = model_with_interactions.predict(X_val_with_interactions)\n",
    "probs_with_interactions = model_with_interactions.predict_proba(X_val_with_interactions)[:, 1]\n",
    "\n",
    "# Evaluate model performance\n",
    "accuracy_without_interactions = accuracy_score(y_val, preds_without_interactions)\n",
    "auc_without_interactions = roc_auc_score(y_val, probs_without_interactions)\n",
    "\n",
    "accuracy_with_interactions = accuracy_score(y_val, preds_with_interactions)\n",
    "auc_with_interactions = roc_auc_score(y_val, probs_with_interactions)\n",
    "\n",
    "# Compare model performance\n",
    "print(\"Model without interactions:\")\n",
    "print(\"Accuracy:\", accuracy_without_interactions)\n",
    "print(\"AUC:\", auc_without_interactions)\n",
    "\n",
    "print(\"\\nModel with interactions:\")\n",
    "print(\"Accuracy:\", accuracy_with_interactions)\n",
    "print(\"AUC:\", auc_with_interactions)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e097a163",
   "metadata": {},
   "source": [
    "Explore using algorithms like random forest and gradient boosting. Compare model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ec61decf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Model:\n",
      "Accuracy: 0.9453805926786751\n",
      "AUC: 0.6788077521610064\n",
      "\n",
      "Gradient Boosting Model:\n",
      "Accuracy: 0.9442184776292853\n",
      "AUC: 0.7464331951509762\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "\n",
    "# Fit Random Forest model\n",
    "rf_model = RandomForestClassifier()\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions with Random Forest model\n",
    "rf_preds = rf_model.predict(X_val)\n",
    "rf_probs = rf_model.predict_proba(X_val)[:, 1]\n",
    "\n",
    "# Evaluate Random Forest model performance\n",
    "rf_accuracy = accuracy_score(y_val, rf_preds)\n",
    "rf_auc = roc_auc_score(y_val, rf_probs)\n",
    "\n",
    "# Fit Gradient Boosting model\n",
    "gb_model = GradientBoostingClassifier()\n",
    "gb_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions with Gradient Boosting model\n",
    "gb_preds = gb_model.predict(X_val)\n",
    "gb_probs = gb_model.predict_proba(X_val)[:, 1]\n",
    "\n",
    "# Evaluate Gradient Boosting model performance\n",
    "gb_accuracy = accuracy_score(y_val, gb_preds)\n",
    "gb_auc = roc_auc_score(y_val, gb_probs)\n",
    "\n",
    "# Compare model performance\n",
    "print(\"Random Forest Model:\")\n",
    "print(\"Accuracy:\", rf_accuracy)\n",
    "print(\"AUC:\", rf_auc)\n",
    "\n",
    "print(\"\\nGradient Boosting Model:\")\n",
    "print(\"Accuracy:\", gb_accuracy)\n",
    "print(\"AUC:\", gb_auc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b92a2a7",
   "metadata": {},
   "source": [
    "Perform the data transformations required by a given algorithm.  For example, some algorithms require numeric data and perform better when it has been standardized or normalized. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ca25b992",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, OneHotEncoder\n",
    "import numpy as np\n",
    "\n",
    "# Concatenate training and validation datasets\n",
    "X_train_val = np.concatenate((X_train, X_val), axis=0)\n",
    "\n",
    "# Standardization\n",
    "scaler = StandardScaler()\n",
    "X_train_val_scaled = scaler.fit_transform(X_train_val)\n",
    "\n",
    "# Normalization\n",
    "normalizer = MinMaxScaler()\n",
    "X_train_val_normalized = normalizer.fit_transform(X_train_val)\n",
    "\n",
    "# One-Hot Encoding\n",
    "encoder = OneHotEncoder()\n",
    "X_train_val_encoded = encoder.fit_transform(X_train_val)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b13fee8f",
   "metadata": {},
   "source": [
    "Experiment with upsampling and downsampling the data to adjust for the imbalanced target variable.  (See APM Ch. 16.)  Does this strategy this improve model performance? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fc75d2f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class Distribution (Before):\n",
      "0    6449\n",
      "1     432\n",
      "Name: TARGET, dtype: int64\n",
      "Accuracy (Original): 0.5758280069726903\n",
      "Accuracy (Upsampled): 0.5764090644973853\n",
      "Accuracy (Downsampled): 0.5758280069726903\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jusha\\New folder\\envs\\daskpy\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils import resample\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import pandas as pd\n",
    "\n",
    "# Assuming 'Cash loans' is a categorical column\n",
    "# Encode the categorical column using one-hot encoding\n",
    "X_encoded = pd.get_dummies(X)\n",
    "\n",
    "# Split the encoded data into training and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_encoded, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Analyze class distribution in the training set\n",
    "class_counts = y_train.value_counts()\n",
    "print(\"Class Distribution (Before):\")\n",
    "print(class_counts)\n",
    "\n",
    "# Upsample the minority class\n",
    "df_majority = X_train[y_train == 0]\n",
    "df_minority = X_train[y_train == 1]\n",
    "\n",
    "df_minority_upsampled = resample(df_minority, replace=True, n_samples=len(df_majority), random_state=42)\n",
    "\n",
    "X_train_upsampled = pd.concat([df_majority, df_minority_upsampled])\n",
    "y_train_upsampled = pd.Series([0] * len(df_majority) + [1] * len(df_minority_upsampled))\n",
    "\n",
    "# Downsample the majority class\n",
    "df_majority_downsampled = resample(df_majority, replace=False, n_samples=len(df_minority), random_state=42)\n",
    "\n",
    "X_train_downsampled = pd.concat([df_majority_downsampled, df_minority])\n",
    "y_train_downsampled = pd.Series([0] * len(df_majority_downsampled) + [1] * len(df_minority))\n",
    "\n",
    "# Train and evaluate models on upsampled and downsampled data\n",
    "model = LogisticRegression()  # Initialize the LogisticRegression model\n",
    "\n",
    "# Train on upsampled data\n",
    "model.fit(X_train_upsampled, y_train_upsampled)\n",
    "y_pred_upsampled = model.predict(X_val)\n",
    "accuracy_upsampled = accuracy_score(y_val, y_pred_upsampled)\n",
    "\n",
    "# Train on downsampled data\n",
    "model.fit(X_train_downsampled, y_train_downsampled)\n",
    "y_pred_downsampled = model.predict(X_val)\n",
    "accuracy_downsampled = accuracy_score(y_val, y_pred_downsampled)\n",
    "\n",
    "# Compute predictions for original data\n",
    "y_pred_original = model.predict(X_val)\n",
    "accuracy_original = accuracy_score(y_val, y_pred_original)\n",
    "\n",
    "# Compare model performance\n",
    "print(\"Accuracy (Original):\", accuracy_original)\n",
    "print(\"Accuracy (Upsampled):\", accuracy_upsampled)\n",
    "print(\"Accuracy (Downsampled):\", accuracy_downsampled)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a243473",
   "metadata": {},
   "source": [
    "Try combining model predictions--this is called an ensemble model--to improve performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d8d68d24",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jusha\\New folder\\envs\\daskpy\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\jusha\\New folder\\envs\\daskpy\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\jusha\\New folder\\envs\\daskpy\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\jusha\\New folder\\envs\\daskpy\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\jusha\\New folder\\envs\\daskpy\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\jusha\\New folder\\envs\\daskpy\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\jusha\\New folder\\envs\\daskpy\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Individual Model 1 Accuracy: 0.9372184855854486\n",
      "Individual Model 2 Accuracy: 0.9372184855854486\n",
      "Individual Model 3 Accuracy: 0.9341667933323201\n",
      "Ensemble Model Accuracy: 0.9453805926786751\n",
      "Ensemble Model Cross-Validation Scores: [0.93681917 0.9375     0.9375     0.9375     0.93677326]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Initialize individual models\n",
    "model1 = RandomForestClassifier()\n",
    "model2 = LogisticRegression()\n",
    "model3 = GradientBoostingClassifier()\n",
    "\n",
    "\n",
    "# Evaluate individual models using cross-validation\n",
    "model1_scores = cross_val_score(model1, X_train, y_train, cv=5, scoring='accuracy')\n",
    "model2_scores = cross_val_score(model2, X_train, y_train, cv=5, scoring='accuracy')\n",
    "model3_scores = cross_val_score(model3, X_train, y_train, cv=5, scoring='accuracy')\n",
    "\n",
    "# Create the ensemble model\n",
    "ensemble_model = VotingClassifier(estimators=[('model1', model1), ('model2', model2), ('model3', model3)])\n",
    "\n",
    "# Evaluate ensemble model using cross-validation\n",
    "ensemble_scores = cross_val_score(ensemble_model, X_train, y_train, cv=5, scoring='accuracy')\n",
    "\n",
    "# Fit the ensemble model on the entire training set\n",
    "ensemble_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions with the ensemble model\n",
    "ensemble_preds = ensemble_model.predict(X_val)\n",
    "\n",
    "# Calculate ensemble model accuracy\n",
    "# Calculate accuracy for each individual model\n",
    "model1_accuracy = np.mean(model1_scores)\n",
    "model2_accuracy = np.mean(model2_scores)\n",
    "model3_accuracy = np.mean(model3_scores)\n",
    "ensemble_accuracy = accuracy_score(y_val, ensemble_preds)\n",
    "\n",
    "# Compare individual models and ensemble model performance\n",
    "print(\"Individual Model 1 Accuracy:\", model1_accuracy)\n",
    "print(\"Individual Model 2 Accuracy:\", model2_accuracy)\n",
    "print(\"Individual Model 3 Accuracy:\", model3_accuracy)\n",
    "print(\"Ensemble Model Accuracy:\", ensemble_accuracy)\n",
    "print(\"Ensemble Model Cross-Validation Scores:\", ensemble_scores)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c4b2490",
   "metadata": {},
   "source": [
    "Try additional feature engineering to boost model performance. Can you combine variables or bin numeric variables?  Explore the notebooks at Kaggle for data transformation ideas. In particular, use the other data sets at Kaggle--beyond the application data--to create additional features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c0821e13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Combine variables\n",
    "# combined_df['NEW_FEATURE'] = combined_df['FEATURE_1'] + combined_df['FEATURE_2']\n",
    "\n",
    "# # Binning numeric variables\n",
    "# combined_df['BINNED_FEATURE'] = pd.cut(combined_df['NUMERIC_FEATURE'], bins=[0, 10, 20, 30], labels=['Low', 'Medium', 'High'])\n",
    "\n",
    "# # Perform additional feature engineering using other datasets\n",
    "# # Assuming `other_df` is another dataset with relevant features\n",
    "# combined_df = pd.merge(combined_df, other_df, on='ID', how='left')\n",
    "\n",
    "# # Explore other datasets at Kaggle for more feature engineering ideas\n",
    "# # You can search for Kaggle notebooks related to your problem domain and explore their feature engineering techniques.\n",
    "\n",
    "# # Split back into original datasets\n",
    "# application_test_df = combined_df[combined_df['DATASET'] == 'application_test']\n",
    "# application_train_df = combined_df[combined_df['DATASET'] == 'application_train']\n",
    "# bureau_df = combined_df[combined_df['DATASET'] == 'bureau']\n",
    "# # ...\n",
    "\n",
    "# # Perform necessary data transformations on individual datasets\n",
    "# # ...\n",
    "\n",
    "# # Continue with model training and evaluation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea363cd1",
   "metadata": {},
   "source": [
    "For machine learning models experiment with hyperparameter tuning  to try to boost performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "346ed10d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters: {'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 100}\n",
      "Best Score: 0.9372184855854486\n",
      "Accuracy: 0.9453805926786751\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Define the hyperparameters and their search space\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [None, 5, 10],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "# Initialize the model\n",
    "model = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Perform grid search with cross-validation\n",
    "grid_search = GridSearchCV(model, param_grid, cv=5, scoring='accuracy')\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best hyperparameter values and model performance\n",
    "best_params = grid_search.best_params_\n",
    "best_score = grid_search.best_score_\n",
    "\n",
    "# Train the model with the best hyperparameters\n",
    "best_model = RandomForestClassifier(**best_params, random_state=42)\n",
    "best_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions using the best model\n",
    "y_pred = best_model.predict(X_val)\n",
    "\n",
    "# Evaluate the model performance\n",
    "accuracy = accuracy_score(y_val, y_pred)\n",
    "\n",
    "# Print the best hyperparameters and model performance\n",
    "print(\"Best Hyperparameters:\", best_params)\n",
    "print(\"Best Score:\", best_score)\n",
    "print(\"Accuracy:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "481c0448",
   "metadata": {},
   "source": [
    "Model performance\n",
    "Describe the performance characteristics of your best model, including run time. What is the train set and test set performance? What is your Kaggle score?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4141baad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Set Performance:\n",
      "AUC: 0.9988425925925926\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      6449\n",
      "           1       1.00      1.00      1.00       432\n",
      "\n",
      "    accuracy                           1.00      6881\n",
      "   macro avg       1.00      1.00      1.00      6881\n",
      "weighted avg       1.00      1.00      1.00      6881\n",
      "\n",
      "Test Set Performance:\n",
      "AUC: 0.5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      1.00      0.97      1627\n",
      "           1       0.00      0.00      0.00        94\n",
      "\n",
      "    accuracy                           0.95      1721\n",
      "   macro avg       0.47      0.50      0.49      1721\n",
      "weighted avg       0.89      0.95      0.92      1721\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jusha\\New folder\\envs\\daskpy\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\jusha\\New folder\\envs\\daskpy\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\jusha\\New folder\\envs\\daskpy\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, roc_auc_score\n",
    "\n",
    "# Train set performance\n",
    "train_pred = best_model.predict(X_train)\n",
    "train_auc = roc_auc_score(y_train, train_pred)\n",
    "print(\"Train Set Performance:\")\n",
    "print(\"AUC:\", train_auc)\n",
    "print(classification_report(y_train, train_pred))\n",
    "\n",
    "# Test set performance\n",
    "test_pred = best_model.predict(X_val)\n",
    "test_auc = roc_auc_score(y_val, test_pred)\n",
    "print(\"Test Set Performance:\")\n",
    "print(\"AUC:\", test_auc)\n",
    "print(classification_report(y_val, test_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04421379",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
